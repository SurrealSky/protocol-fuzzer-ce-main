[[Recipe_LinuxNetServer]]
=== Recipe: Monitoring a Linux Network Service

This recipe describes the base setup needed to fuzz a Linux network service.
When fuzzing a network server, Peach impersonates the client, the other endpoint of the
network connection.

The recipe is a model that you can follow closely. Or, you can use the model as
a starting point and augment the model for your specific situation. This recipe
consists of the following parts:

1.	The workflow for the fuzzing session
2.	The Peach components to use in configuring the fuzzing setup
This section focuses on the monitoring needs and the agents that house the monitors.
3.	Configuration settings used to fuzz a sample service (SNMP) running this workflow

IMPORTANT: Assumptions/Givens in this recipe are that a Pit is ready to use, Peach is ready to run, and any software module needed to perform the fuzzing job is installed.

In this scenario, Peach runs on a host computer; the network server runs in a
Virtual Machine (VM) on the host. With Peach running on the host, it controls the
environment. If the network server crashes, the worst thing that happens is that
the virtual machine has to restart. Peach recover the data if the network
server crashes.

==== Workflow for the Fuzzing Session

The workflow lists the task sequence that occurs when running the fuzzing session.
The setup needed to implement the workflow follows in the next section. Start with
defining the workflow, especially if you plan to embellish the recipe.

Here is the workflow that Peach performs in fuzzing a Linux network service:

1. Revert to a virtual machine snapshot.
2. Wait for the machine to boot up.
3. Launch the network service.
4. Perform fuzzing. Create and run test cases.

* Peach initiates contact with the server and sends packets of fuzzed data to the server.
* Check for faults, such as crashes and access violations.

5. When a fault occurs, do the following:

..	Collect data surrounding the test case.
..	Revert to the VM snapshot.
..	Launch the network service.

6.	Loop to step 4 (resume fuzzing).


==== Peach Components Needed in the Fuzzing Configuration

Defining the Peach components divides in two parts: identifying the monitors to use in the configuration and identifying where to locate the specified monitors.

===== Identifying Monitors

This part of the recipe revisits each step of the workflow to identify the monitors needed to implement the configuration:

1. Revert to a snapshot of a virtual machine.
+
Peach needs to automate the test environment and remove human interaction during the fuzzing job. We place the service in a virtual machine (VM) because Peach can use a VM monitor to automatically start and reset the test environment when needed.
+
The VM snapshot is taken while the guest OS and the Peach agent are running. Using such a snapshot avoids the wait time associated with booting up the virtual machine. Also, the same snapshot is used when Peach refreshes the test environment after a fault occurs.
+
The monitor for the VM environment, xref:Monitors_Vmware[VMware] monitor, resides on the host machine.

2. Wait for the machine to boot up.
+
Peach waits for the VM snapshot to resume.

3. Launch the network service.
+
The Peach agent in the VM starts the network service via the xref:Monitors_Gdb[Gdb] debugging monitor and the GDB system debugger.

4. Perform fuzzing, checking for faults.
+
Perform fault detection in the VM. The Gdb monitor watches the internals of the services and detects faults such as access violations and exceptions. Again, the debug monitor is located on the same machine as the service.

5. Collect data surrounding each fault as it happens.
+
Peach sends and receives network packets to the service. When a fault occurs, the packets involved with the fault are interesting. Peach captures the packets using the xref:Monitors_NetworkCapture[NetworkCapture] monitor.
+
Peach collects log files generated by the debugger located on the remote machine where the service resides. A xref:Monitors_SaveFile[Save File] monitor sends files from a specified folder on the remote system to the Peach logging repository on the local machine.

6. Resume fuzzing.
+
This step uses the VM monitor and VM snapshot from step 1 to refresh the test environment, and the debug monitor from step 3 to start the network service in the refreshed environment. No additional monitors are needed for this step.

===== Identifying Agents

Peach offers two types of agents to manage monitors and I/O publishers: local and remote.

* Local agents reside inside Peach. +
The local agent in this recipe addresses automation involving the VM and data collection
that captures network packets. The local agent houses the xref:Monitors_Vmware[VMware]
 and the xref:Monitors_NetworkCapture[NetworkCapture] monitors.
+
The VMware monitor starts a snapshot VM environment at the beginning of the fuzzing job,
as well as restarting the same VM snapshot after a fault occurs.

* Remote agents reside in separate processes on remote machines with the test targets. +
In this case, the remote agent and the Linux service reside on the same machine.
+
The remote agent houses the xref:Monitors_Gdb[Gdb] debug monitor that starts the
network service at the beginning of the fuzzing job and restarts the service in the
refreshed environment after a fault. The Gdb debug monitor detects faults that occur in
the service.
+
In addition, a data collection monitor collects log files after a fault occurs in the network service. The xref:Monitors_SaveFile[Save File] monitor forwards the log files to the logging repository.

The result is that we end up with the following configuration:

image::{images}/UserGuide/Recipes/VM_Remote_Agent.png[scale="50"]

Peach is located on one machine with a local agent that houses the VM monitor and the Network capture monitor. A second agent resides on the remote machine with the service. The remote agent houses the Gdb debug monitor and the SaveFile monitor.

The local agent is simple to implement. All that's needed is to define the agent, then specify the appropriate monitors and monitor settings used with the local agent.

The remote monitor is a little more involved. Like the local agent, the remote agent needs to be defined, then specify the appropriate monitors and monitor settings used with the remote agent. Second, the remote agent needs to run on the same OS as the test target. This step can be done separately from specifying the configuration details. In this recipe, a VM snapshot is used. See the previous section, Using Virtual Machines, for information on setting up the VM snapshot.

==== Sample configuration

This section shows the recipe implemented for a network service and consists of the following items:

* Setup on the Target VM Image
* Pit variables
* Peach agents
* Peach monitors
* Configuration test

===== Setup on the Target VM Image

Perform the following items on the VM before taking a snapshot of the VM.

1.	Run the Peach agent from a shell with root access. +
Within the shell, navigate to the peach folder and execute the following command: +
`./peach -a tcp` +
When Peach starts the VM, the Peach agent is running in a root shell. +

2.	In the VM, edit the configuration file to have the service listen for
connections on all IPv4 interfaces.
3.	Stop the service. +
During fuzzing, the debugger (GDB) will start the service.

===== Pit Variables

The following UI display identifies data values typically needed by a network
protocol Pit. The variables and values are independent of the monitors used in
the configuration. Pit variables are unique to the Pit and might differ with those
in the example illustration.

image::{images}/UserGuide/Recipes/LinuxNetService_PitVariables.png[scale="50"]

The Pit User Guides describe the Pit-specific variables.

Community String (Authentication):: Community string used for authentication by the network server. Check the network service documentation for consistency of this value. If needed, change the value here to coincide with the value expected by the test target.

Source Port:: Port number of the local machine that sends packets to the server. Several services use well-known ports that usually can be left unedited.

Target IPv4 Address:: IPv4 address of the target machine (server). For information on obtaining the IPv4 address, see Retrieving Machine Information in the Pit documentation.

Target Port:: Port number of the server that receives packets. Several services use well-known ports that usually can be left unedited.

Timeout:: Duration, in milliseconds, to wait for incoming data.During fuzzing, a timeout failure causes the fuzzer to skip to the next test case.

===== Agents

The following UI diagram acts as an overview, showing the Peach agents and the monitors within each agent. Peach uses the ordering within the agent to determine the order in which to load and run monitors.

image::{images}/UserGuide/Recipes/LinuxNetService_Agents.png[scale="50"]

The local agent is defined first and lists the default information for both name and location. This definition for a local agent is typical and, otherwise, unremarkable. The Vmware monitor, that starts the virtual machine, is the first monitor listed, as that action is not dependent on actions from another monitor.

The remote agent, named "Remote", has quite a different location specification. The location consists of concatenated pieces of information:

* Channel. The channel for a remote agent is `tcp`. A colon and two forward slashes separate the channel from the IPv4 address of the hardware interface.
* IPv4 address. The IPv4 address of the agent is the second component of the location. Use `ifconfig` to  find this address of the remote machine.

The monitor list within each agent is significant, as the monitors are launched in order from top to bottom within an agent.

===== Monitors

This recipe uses four monitors, two on the machine with Peach and two on the remote machine. The recipe shows each monitor and describes its roles: fault detection, data collection, and automation.

====== Vmware (Linux virtual machine Automation)

The xref:Monitors_Vmware[Vmware] monitor controls setting up and starting the virtual machine.

image::{images}/UserGuide/Recipes/LinuxNetService_Vmware.png[scale="50"]

The most significant parameters for the VMware monitor follow:

Vmx:: Identifies the full path of the virtual machine image. Peach loads the snapshot of the VM image at the start of the fuzzing job and after a fault occurs.

Headless:: Identifies whether the VM has a window associated with it. When
developing a configuration, set this parameter to false. When the configuration
is complete, change Headless to true.

Host Type:: Specifies the VMware product used in the configuration.

Snapshot Name:: Identifies the snapshot to use for the specific image.


===== Network Capture (InterestingPackets)

The xref:Monitors_NetworkCapture[Netowrk Capture Monitor (InterestingPackets)] captures
network packets sent and received from the test target. When a fault occurs,
Peach stores the packets immediately surrounding the fault in the log of the
test case.

image::{images}/UserGuide/Recipes/LinuxNetService_NetworkCapture.png[scale="50"]

The most significant parameters for the network capture monitor follow:

Device:: Specifies the name of the interface on the local machine (the machine
with Peach) used to communicate with the test target. Use `ifconfig` to identify
the interface(s) available for use.

[NOTE]
=======
You can find the appropriate host interface that communicates with the VM using the following steps:

1. Collect a list of interfaces (and their IPv4 addresses) by running `ipconfig` or `ifconfig`.
2. Test each interface in the list. Manually run a capture session with Wireshark using an interface from the list.
3. On the host machine, Ping the target IPv4 (of the VM).
4. If the correct interface of the host is used, you'll see the Ping request and reply packet exchanges through Wireshark,
5. Loop to step 2 and repeat, using another interface.

=======

Filter:: Helps capture only those packets associated with the fuzzing session.
The filter adheres to the syntax and requirements of the Pcap filter specification.

TIP: WireShark refers to the Libpcap filters as capture filters. Use the capture
filters. Wireshark also defines its own display filters that it uses to filter entries in its session files. The display filters are not compatible with Libpcap.

===== Gdb (Debugger)

The xref:Monitors_Gdb[Gdb] debugger monitor performs two main functions in this recipe:

* Starts the network service at the start of a fuzzing job and restarts the service
when the VM snapshot refreshes.
* Detects faults internal to the service.

image::{images}/UserGuide/Recipes/LinuxNetService_Gdb.png[scale="50"]

The most significant parameters follow:

Executable:: Identifies the full path to the Linux service executable.
This monitor, managed by the remote agent, resides on the remote machine, so the
full path is for the Linux file system.

Arguments:: Arguments for the executable.

===== SaveFile (CollectLogs)

The xref:Monitors_SaveFile[SaveFile] monitor collects log files from the remote test target and copies them to the Peach Logging folder. The monitor is housed by the remote agent.

image::{images}/UserGuide/Recipes/LinuxNetService_SaveFile.png[scale="50"]

The most significant parameter follows:

Filename:: Specifies the full path to the Linux logging system used by GDB.

===== Configuration Test

Once the monitors and associated parameters are part of the configuration, you can test the configuration. From the Configuration menu along the left edge of the window, click on `Test` to run a single iteration (test case) on the configuration. Note that the test checks the connections and communications. It does NOT do any fuzzing.

For more information on testing a configuration, see xref:Test_PitConfiguration[Test Pit Configuration].
